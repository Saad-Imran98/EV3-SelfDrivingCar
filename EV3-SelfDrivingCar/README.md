# RoboticsProject19
Heres the beauty in all his robotic glory (we named him Trevor):
<blockquote class="imgur-embed-pub" lang="en" data-id="a/WPalATO"  ><a href="//imgur.com/a/WPalATO">Trevor the Autonomous Robot</a></blockquote>

# Introduction
An autonomously navigating car using an EV3 and the Lejos API. Our goal was to make a car with autonomous driving capabilities that can navigate a circuit with multiple destinations on its own. This task involved the following problems that we needed to find solutions to: driving itself on roads, finding the shortest path to a user given destination and also avoiding obstacles like a human driven car would. Firstly, I will explain the basics of what an EV3 is, how it works and what it is capable of. Next, we needed a frame to hold together the EV3, Android phone, sensors and motors; I will explain the process of designing and building our car and the considerations that were made to build something that could work well for us. There were two programs required for the project, one on the EV3 and another on the Android side on an App running to help the robot read QR codes. I will be explaining both parts.

# The Lego Mindstorms EV3
Lego has been making robotic kits since 1998 under the name Mindstorms. The motivation behind the kit was to give anyone the freedom to build and program their Lego creation to do anything they want. It came with its own software that made the complicated world of robotics easier to approach.
The EV3 kits include the main brick that you can use to connect the sensors and motors that come with it. It runs on its own software, designed to be easier and simpler to make your own programs. However, for our purposes we used Lejos, a java API that has many built in functions that can control different aspects of the robot such as motors. This gave us more control over the robot’s functions and allowed us to program it using Java. As for physical tools, for our build we used two motors, an ultrasonic sensor for proximity and a color sensor to follow a black line meant to represent a road.

# Construction of the Car
We gradually landed on our current design through lots of trial and error. However, the group already came to a consensus on the key components; the cage to hold all sensors, Ackermann steering and the phone placeholder.

Since there were a lot of parts such as sensors and an android phone, the cage needed to be sturdy and solid enough to not break under movements from the robot. This proved difficult as Lego isn’t the sturdiest material. With large rectangular pieces as the main cage and smaller pieces to reinforce the design we managed to build a cube-like cage that we could use as the base for our car. It spanned the entire robot and did well to hold the heaviest component, the ev3 brick on the top of it. Around it we had the freedom to place sensors and on the underside the Ackermann steering and back wheels.
The Ackermann steering was an essential part of our design that let it turn like a real car. Ackerman Steering is used to prevent the outer back wheel of a car from skidding while it turns. This happens because when a car turns, the outer wheel needs to turn at a lesser angle due to its larger distance to the origin of the turn than the inner wheel. In simpler terms, it is a more efficient and realistic way a car would turn than using two wheels that turn at the same angle.
The android placeholder was a crucial part of the robot since we were using the android phone as an extra set of sensors for our autonomous car. The placeholder was quite simple, it was another cage similar to the one we built as our base. It attached to the back of the car a bit like a pick-up truck. We used this to hold and angle the phone downward towards the ground where the camera needed to be.

# The Lejos API and our Java Code
The Lejos API helped us set up the meat and potatoes of our code. Using the documentation, we picked the classes we needed to control and set up all the sensors such as the ultrasonic sensor and light sensor as well as the motors. Some built in Lejos classes weren’t working as we wanted to in which case we modified them.
Our first problem was with the motors. Lejos has built in steering pilots that help make the control of motors simpler and allow you, or another program to control the steering. This works by passing the pilot motors that control your steering and power (thrust). However, the built-in ones did not work for us, so we made our own simpler version of the steering pilot. Its main functions were to pilot the robot of course, but also to correctly re-center the wheels after it has made a turn. It also more realistically turned slowly into a turn like a real car instead of snapping furiously to the left or right.
Furthermore, the car had to navigate a road accurately and we found a way to do this using a line following PID controller class. See it in action here: <blockquote class="imgur-embed-pub" lang="en" data-id="gh80e8A"><a href="https://imgur.com/gh80e8A">View post on imgur.com</a></blockquote> This class followed black lines accurately using the light sensor values. Firstly, It always moved forward in the direction of the black line when it detected a minimal light value since black does not reflect light well. This allowed it to know that it is on the black line and going the right way. Then, when it detected a higher light value such as the white of paper, it turned back towards where it expects the black line to be. This may happen when there is a turn or end of a road.
Next, we needed a way to read QR codes since we would use this later for navigation purposes. We achieved this through using an Android app that utilizes the phone’s camera and a server. The server on the app communicates through Bluetooth and sends a message to the ev3 Lejos program every time it reads a message from a QR code. On the EV3 side, a socket is created in the robot’s runtime Lejos program to send and receive messages. The Android app was solely my domain in the group, since nobody else had any prior experience. I used Android studio to build the app on our devices and make relevant tweaks to the base program given to us by our professor. Additionally, for testing and also fun I made a controller “Activity” which in android terms is a separate page or screen. It had turn commands and stop commands and we used it to test the input stream and also drive it around wirelessly like a remote-control car.

Proceeding with a moving robot and one that can read QR codes, now we needed a way for it to find its paths around a map. We used Lejos’s Dijkstra’s path finding to do this. It worked by giving the algorithm a start-point and an end-point and returned the shortest path between those two points. This was done by giving it a line map containing coordinates to all the roads, junctions, edges as well as places to avoid, which in our case was anywhere but roads. Then, by giving it a start and end point it gave the robot directions to the end point in the shortest possible path.
The last module of code was the selection menu. It helped the user select a destination by displaying a list of available destinations. After the user selects a destination it would load directions that the robot would then continue to follow and display it while it moves, similar to how google maps works while you are driving and following directions.
The code would not work without a main controller pulling all the strings and making sure everything works well together. To achieve this, all the classes and methods we built were used in behaviors and an arbitrator. A behavior is an action a robot is always looking to do or is doing already, while the arbitrator is what prioritizes and runs each behavior. It is essentially the brain of the robot telling it what to do all the time and in what order.

# The Map
We wanted a map that showcased the full potential of our robot. This meant having sharp turns, junctions and multiple destinations. We decided on having a prison, gym, library, pool and school as our destinations. Each of them had QR codes and so did every turn and end of a road. We quickly learned through testing of Dijkstra’s path finding that the more points we have on the line map, the more accurately the algorithm will find a shortest path.
To build the map we digitally designed it and printed it out to a scale large enough for our robot to fit on the map and the roads be wide enough so that the light sensor follows the lines accurately. Getting the size right took trial and error. The end result was quite big but it worked well enough to accommodate the car’s size.

# Running the Main Code
This is what the main program looked like. It contained the instructions to initialize the behaviors that we worked on throughout the project as well as the arbitrator that ran the behaviors. Apart from behaviors we had a few different states, Start, Going, Moving and Stop. This represented the steps for a successful run that an autonomous car would go through.
In a successful run, the ‘PID line following controller’ behavior runs at all times and the car would follow a road until it reaches a destination QR code. This is detected because the android socket is also always on and receiving messages from the phone. After receiving the message, it then stops and asks the user for a destination. Next the user inputs a destination and it calculates the shortest path and goes towards the directions it is given by Dijkstra’s algorithm. Encountering QR codes on the way allows it to know where it has reached and if it needs to turn, keep going straight or stop. During the car’s travel the ‘Distance Stop’ behavior always runs and if the ultrasonic sensor encounters an object near the car’s path, it stops and waits till it has moved from its path. Finally, the car reaches its destination and stops after displaying a “Destination reached” message on the screen of the EV3.

# Reflection
Working in a team environment was a pleasant experience for me. It allowed us to all designate various parts of the project to each other and play to our strengths allowing us to work on the parts we’d do best in.
This was especially helpful while building the components for our robot since it was the most labor-intensive part of our project. Some of us were more experienced with Lego and willing to build than others and so it helped to split the work load into designing or building.
In our group we usually coded in pairs of two. In doing so we got a lot more done than we would have individually and also had an extra pair of eyes to keep track of mistakes and things that could be improved or a solution that could be implemented more efficiently.
All in all, it was fun working in a team. Brainstorming ideas together was my favorite part since as a group, we came up with great and creative ideas. Apart from this due to the nature of group work, we relied on each other to finish our tasks which helped us keep ourselves in check and provide feedback to push ourselves to come up with the best work we can.

# Conclusion
Working with EV3 Mindstorms and Lejos was a great experience. Through learning about the basics of the robot and how it works gave me valuable technical experience and it building the car was very enjoyable too. Using Lejos taught me how API’s work and how to use one to work on projects of my own and with that came the ability to read and utilize API documentation which is a great skill. Last but not least, I learned to work well in a team environment and how to play to each other’s strengths to break down large problems into smaller more manageable ones.
